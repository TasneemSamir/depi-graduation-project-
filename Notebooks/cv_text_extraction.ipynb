{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Note: Tesseract OCR engine must be installed separately\n",
        "# Windows: https://github.com/UB-Mannheim/tesseract/wiki\n",
        "# macOS: brew install tesseract\n",
        "# Linux: sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "id": "v8-eP_LCP2F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzzZDBKrsHBY",
        "outputId": "04bbf85a-c16e-46de-df1a-47f6099aa3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, pytesseract, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.5 pytesseract-0.3.13 python-docx-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub opencv-python pytesseract numpy Pillow PyMuPDF python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bfhiSKPennLM",
        "outputId": "3e3a39aa-7566-4be1-a394-3edcaa2c79ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "OPTION 4: Process ALL Nested Folders\n",
            "------------------------------------------------------------\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/youssefkhalil/resumes-images-datasets?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.62G/2.62G [00:19<00:00, 147MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SCANNING NESTED FOLDERS\n",
            "============================================================\n",
            "Root directory: /root/.cache/kagglehub/datasets/youssefkhalil/resumes-images-datasets/versions/1\n",
            "\n",
            "Found 12646 total images\n",
            "Found 99 categories:\n",
            "  - Accountant: 492 images\n",
            "  - Accountant resumes: 67 images\n",
            "  - Advocate: 453 images\n",
            "  - Advocate resumes: 94 images\n",
            "  - Agricultural: 397 images\n",
            "  - Agricultural resumes: 68 images\n",
            "  - Agriculture: 167 images\n",
            "  - Apparel: 145 images\n",
            "  - Apparel resumes: 51 images\n",
            "  - Architect: 176 images\n",
            "  - Architects resumes: 60 images\n",
            "  - Arts: 463 images\n",
            "  - Arts resumes: 83 images\n",
            "  - Automobile: 156 images\n",
            "  - Automobile resumes: 40 images\n",
            "  - Avian: 72 images\n",
            "  - Aviation: 251 images\n",
            "  - Aviation resumes: 51 images\n",
            "  - BPO resumes: 30 images\n",
            "  - Banking: 307 images\n",
            "  - Banking resumes: 41 images\n",
            "  - Blockchain: 49 images\n",
            "  - Blockchain resumes: 9 images\n",
            "  - Building: 7 images\n",
            "  - Building _Construction resumes: 55 images\n",
            "  - Business Analyst resumes: 64 images\n",
            "  - BusinessAnalyst: 80 images\n",
            "  - Civil Engineer resumes: 89 images\n",
            "  - CivilEngineer: 81 images\n",
            "  - Consult: 210 images\n",
            "  - Consultant: 148 images\n",
            "  - Consultant resumes: 71 images\n",
            "  - DOT: 140 images\n",
            "  - Data Science: 400 images\n",
            "  - DataScience: 49 images\n",
            "  - Database: 190 images\n",
            "  - Database resumes: 75 images\n",
            "  - Design: 139 images\n",
            "  - Designer: 403 images\n",
            "  - Designing resumes: 39 images\n",
            "  - DevOps Engineer: 144 images\n",
            "  - DevOps Engineer resumes: 87 images\n",
            "  - DevOpsEngineer: 69 images\n",
            "  - Digital: 181 images\n",
            "  - Digital Media: 129 images\n",
            "  - Digital Media resumes: 68 images\n",
            "  - DotNet Developer resumes: 63 images\n",
            "  - ETL: 73 images\n",
            "  - ETL Developer: 154 images\n",
            "  - ETL Developer resumes: 65 images\n",
            "  - Education: 217 images\n",
            "  - Education resumes: 55 images\n",
            "  - Electrical Engineering resumes: 79 images\n",
            "  - ElectricalEngineer: 117 images\n",
            "  - Finance: 182 images\n",
            "  - Finance resumes: 56 images\n",
            "  - Food: 172 images\n",
            "  - Food_Beverages resumes: 62 images\n",
            "  - HR: 81 images\n",
            "  - HR resumes: 85 images\n",
            "  - HealthFitness: 64 images\n",
            "  - Health_Fitness resumes: 76 images\n",
            "  - Human Resources: 405 images\n",
            "  - IT: 172 images\n",
            "  - Information Technology: 139 images\n",
            "  - Information Technology resumes: 50 images\n",
            "  - Java Developer resumes: 78 images\n",
            "  - JavaDeveloper: 80 images\n",
            "  - Management: 356 images\n",
            "  - Managment resumes: 64 images\n",
            "  - Mechanical Engineer resumes: 104 images\n",
            "  - MechanicalEngineer: 86 images\n",
            "  - NSE: 77 images\n",
            "  - Network Security Engineer resumes: 64 images\n",
            "  - OperationManager: 76 images\n",
            "  - Operations Manager resumes: 78 images\n",
            "  - PBO: 158 images\n",
            "  - PMO: 57 images\n",
            "  - PMO resumes: 52 images\n",
            "  - Public: 151 images\n",
            "  - Public Relations resumes: 68 images\n",
            "  - Python Developer: 142 images\n",
            "  - Python Developer resumes: 58 images\n",
            "  - PythonDeveloper: 51 images\n",
            "  - React: 40 images\n",
            "  - React Developer: 396 images\n",
            "  - React Developer resumes: 18 images\n",
            "  - SAP Developer: 150 images\n",
            "  - SAP Developer resumes: 64 images\n",
            "  - SAPDeveloper: 50 images\n",
            "  - SQL: 120 images\n",
            "  - SQL Developer resumes: 82 images\n",
            "  - Sales: 79 images\n",
            "  - Sales resumes: 90 images\n",
            "  - Testing: 436 images\n",
            "  - Testing resumes: 76 images\n",
            "  - WebDesigning: 59 images\n",
            "  - data science resumes: 120 images\n",
            "  - web designing resumes: 59 images\n",
            "\n",
            "============================================================\n",
            "STARTING PROCESSING\n",
            "============================================================\n",
            "\n",
            "Processing 1/12646: [Designing resumes] Image_3.png\n",
            "Processing 2/12646: [Designing resumes] Image_21.png\n",
            "Processing 3/12646: [Designing resumes] Image_6.png\n",
            "Processing 4/12646: [Designing resumes] Image_1.jpg\n",
            "Processing 5/12646: [Designing resumes] Image_82.jpg\n",
            "Processing 6/12646: [Designing resumes] Image_23.png\n",
            "Processing 7/12646: [Designing resumes] Image_58.png\n",
            "Processing 8/12646: [Designing resumes] Image_4.jpg\n",
            "Processing 9/12646: [Designing resumes] Image_82.png\n",
            "Processing 10/12646: [Designing resumes] Image_19.jpg\n",
            "Processing 11/12646: [Designing resumes] Image_52.jpg\n",
            "Processing 12/12646: [Designing resumes] Image_30.jpg\n",
            "Processing 13/12646: [Designing resumes] Image_35.jpg\n",
            "Processing 14/12646: [Designing resumes] Image_15.jpg\n",
            "Processing 15/12646: [Designing resumes] Image_69.jpg\n",
            "Processing 16/12646: [Designing resumes] Image_51.png\n",
            "Processing 17/12646: [Designing resumes] Image_27.png\n",
            "Processing 18/12646: [Designing resumes] Image_72.png\n",
            "Processing 19/12646: [Designing resumes] Image_12.png\n",
            "Processing 20/12646: [Designing resumes] Image_22.png\n",
            "Processing 21/12646: [Designing resumes] Image_10.png\n",
            "Processing 22/12646: [Designing resumes] Image_36.jpg\n",
            "Processing 23/12646: [Designing resumes] Image_57.jpg\n",
            "Processing 24/12646: [Designing resumes] Image_49.png\n",
            "Processing 25/12646: [Designing resumes] Image_48.png\n",
            "Processing 26/12646: [Designing resumes] Image_29.jpg\n",
            "Processing 27/12646: [Designing resumes] Image_50.jpg\n",
            "Processing 28/12646: [Designing resumes] Image_31.jpg\n",
            "Processing 29/12646: [Designing resumes] Image_92.jpg\n",
            "Processing 30/12646: [Designing resumes] Image_25.png\n",
            "Processing 31/12646: [Designing resumes] Image_55.jpg\n",
            "Processing 32/12646: [Designing resumes] Image_64.jpg\n",
            "Processing 33/12646: [Designing resumes] Image_70.jpg\n",
            "Processing 34/12646: [Designing resumes] Image_7.jpg\n",
            "Processing 35/12646: [Designing resumes] Image_23.jpg\n",
            "Processing 36/12646: [Designing resumes] Image_3.jpg\n",
            "Processing 37/12646: [Designing resumes] Image_32.png\n",
            "Processing 38/12646: [Designing resumes] Image_59.jpg\n",
            "Processing 39/12646: [Designing resumes] Image_28.jpg\n",
            "Processing 40/12646: [Network Security Engineer resumes] Image_96.png\n",
            "Processing 41/12646: [Network Security Engineer resumes] Image_63.png\n",
            "Processing 42/12646: [Network Security Engineer resumes] Image_74.jpg\n",
            "Processing 43/12646: [Network Security Engineer resumes] Image_24.png\n",
            "Processing 44/12646: [Network Security Engineer resumes] Image_76.jpg\n",
            "Processing 45/12646: [Network Security Engineer resumes] Image_20.jpg\n",
            "Processing 46/12646: [Network Security Engineer resumes] Image_88.png\n",
            "Processing 47/12646: [Network Security Engineer resumes] Image_41.jpg\n",
            "Processing 48/12646: [Network Security Engineer resumes] Image_58.jpg\n",
            "Processing 49/12646: [Network Security Engineer resumes] Image_68.jpg\n",
            "Processing 50/12646: [Network Security Engineer resumes] Image_63.jpg\n",
            "Processing 51/12646: [Network Security Engineer resumes] Image_4.jpg\n",
            "Processing 52/12646: [Network Security Engineer resumes] Image_95.png\n",
            "Processing 53/12646: [Network Security Engineer resumes] Image_39.png\n",
            "Processing 54/12646: [Network Security Engineer resumes] Image_44.jpg\n",
            "Processing 55/12646: [Network Security Engineer resumes] Image_19.jpg\n",
            "Processing 56/12646: [Network Security Engineer resumes] Image_71.png\n",
            "Processing 57/12646: [Network Security Engineer resumes] Image_52.jpg\n",
            "Processing 58/12646: [Network Security Engineer resumes] Image_40.jpg\n",
            "Processing 59/12646: [Network Security Engineer resumes] Image_42.png\n",
            "Processing 60/12646: [Network Security Engineer resumes] Image_30.png\n",
            "Processing 61/12646: [Network Security Engineer resumes] Image_13.png\n",
            "Processing 62/12646: [Network Security Engineer resumes] Image_15.jpg\n",
            "Processing 63/12646: [Network Security Engineer resumes] Image_88.jpg\n",
            "Processing 64/12646: [Network Security Engineer resumes] Image_71.jpg\n",
            "Processing 65/12646: [Network Security Engineer resumes] Image_27.png\n",
            "Processing 66/12646: [Network Security Engineer resumes] Image_78.jpg\n",
            "Processing 67/12646: [Network Security Engineer resumes] Image_90.png\n",
            "Processing 68/12646: [Network Security Engineer resumes] Image_98.jpg\n",
            "Processing 69/12646: [Network Security Engineer resumes] Image_77.jpg\n",
            "Processing 70/12646: [Network Security Engineer resumes] Image_9.jpg\n",
            "Processing 71/12646: [Network Security Engineer resumes] Image_36.jpg\n",
            "Processing 72/12646: [Network Security Engineer resumes] Image_45.jpg\n",
            "Processing 73/12646: [Network Security Engineer resumes] Image_57.jpg\n",
            "Processing 74/12646: [Network Security Engineer resumes] Image_89.png\n",
            "Processing 75/12646: [Network Security Engineer resumes] Image_7.png\n",
            "Processing 76/12646: [Network Security Engineer resumes] Image_29.jpg\n",
            "Processing 77/12646: [Network Security Engineer resumes] Image_50.jpg\n",
            "Processing 78/12646: [Network Security Engineer resumes] Image_62.jpg\n",
            "Processing 79/12646: [Network Security Engineer resumes] Image_91.png\n",
            "Processing 80/12646: [Network Security Engineer resumes] Image_31.jpg\n",
            "Processing 81/12646: [Network Security Engineer resumes] Image_86.jpg\n",
            "Processing 82/12646: [Network Security Engineer resumes] Image_55.png\n",
            "Processing 83/12646: [Network Security Engineer resumes] Image_95.jpg\n",
            "Processing 84/12646: [Network Security Engineer resumes] Image_17.jpg\n",
            "Processing 85/12646: [Network Security Engineer resumes] Image_34.jpg\n",
            "Processing 86/12646: [Network Security Engineer resumes] Image_16.jpg\n",
            "Processing 87/12646: [Network Security Engineer resumes] Image_85.jpg\n",
            "Processing 88/12646: [Network Security Engineer resumes] Image_37.jpg\n",
            "Processing 89/12646: [Network Security Engineer resumes] Image_94.jpg\n",
            "Processing 90/12646: [Network Security Engineer resumes] Image_33.png\n",
            "Processing 91/12646: [Network Security Engineer resumes] Image_5.jpg\n",
            "Processing 92/12646: [Network Security Engineer resumes] Image_2.jpg\n",
            "Processing 93/12646: [Network Security Engineer resumes] Image_83.png\n",
            "Processing 94/12646: [Network Security Engineer resumes] Image_38.jpg\n",
            "Processing 95/12646: [Network Security Engineer resumes] Image_86.png\n",
            "Processing 96/12646: [Network Security Engineer resumes] Image_100.png\n",
            "Processing 97/12646: [Network Security Engineer resumes] Image_83.jpg\n",
            "Processing 98/12646: [Network Security Engineer resumes] Image_87.jpg\n",
            "Processing 99/12646: [Network Security Engineer resumes] Image_97.png\n",
            "Processing 100/12646: [Network Security Engineer resumes] Image_28.jpg\n",
            "Processing 101/12646: [Network Security Engineer resumes] Image_96.jpg\n",
            "Processing 102/12646: [Network Security Engineer resumes] Image_18.jpg\n",
            "Processing 103/12646: [Network Security Engineer resumes] Image_40.png\n",
            "Processing 104/12646: [ETL Developer resumes] Image_96.png\n",
            "Processing 105/12646: [ETL Developer resumes] Image_21.jpg\n",
            "Processing 106/12646: [ETL Developer resumes] Image_1.jpg\n",
            "Processing 107/12646: [ETL Developer resumes] Image_39.jpg\n",
            "Processing 108/12646: [ETL Developer resumes] Image_60.jpg\n",
            "Processing 109/12646: [ETL Developer resumes] Image_99.png\n",
            "Processing 110/12646: [ETL Developer resumes] Image_52.png\n",
            "Processing 111/12646: [ETL Developer resumes] Image_75.jpg\n",
            "Processing 112/12646: [ETL Developer resumes] Image_57.png\n",
            "Processing 113/12646: [ETL Developer resumes] Image_26.jpg\n",
            "Processing 114/12646: [ETL Developer resumes] Image_20.jpg\n",
            "Processing 115/12646: [ETL Developer resumes] Image_47.jpg\n",
            "Processing 116/12646: [ETL Developer resumes] Image_58.jpg\n",
            "Processing 117/12646: [ETL Developer resumes] Image_87.png\n",
            "Processing 118/12646: [ETL Developer resumes] Image_68.jpg\n",
            "Processing 119/12646: [ETL Developer resumes] Image_11.png\n",
            "Processing 120/12646: [ETL Developer resumes] Image_4.jpg\n",
            "Processing 121/12646: [ETL Developer resumes] Image_6.jpg\n",
            "Processing 122/12646: [ETL Developer resumes] Image_59.png\n",
            "Processing 123/12646: [ETL Developer resumes] Image_82.png\n",
            "Processing 124/12646: [ETL Developer resumes] Image_19.jpg\n",
            "Processing 125/12646: [ETL Developer resumes] Image_67.jpg\n",
            "Processing 126/12646: [ETL Developer resumes] Image_71.png\n",
            "Processing 127/12646: [ETL Developer resumes] Image_40.jpg\n",
            "Processing 128/12646: [ETL Developer resumes] Image_70.png\n",
            "Processing 129/12646: [ETL Developer resumes] Image_63.JPG\n",
            "Processing 130/12646: [ETL Developer resumes] Image_88.jpg\n",
            "Processing 131/12646: [ETL Developer resumes] Image_71.jpg\n",
            "Processing 132/12646: [ETL Developer resumes] Image_74.png\n",
            "Processing 133/12646: [ETL Developer resumes] Image_49.jpg\n",
            "Processing 134/12646: [ETL Developer resumes] Image_51.png\n",
            "Processing 135/12646: [ETL Developer resumes] Image_27.png\n",
            "Processing 136/12646: [ETL Developer resumes] Image_12.png\n",
            "Processing 137/12646: [ETL Developer resumes] Image_90.png\n",
            "Processing 138/12646: [ETL Developer resumes] Image_98.jpg\n",
            "Processing 139/12646: [ETL Developer resumes] Image_77.jpg\n",
            "Processing 140/12646: [ETL Developer resumes] Image_9.jpg\n",
            "Processing 141/12646: [ETL Developer resumes] Image_45.jpg\n",
            "Processing 142/12646: [ETL Developer resumes] Image_69.png\n",
            "Processing 143/12646: [ETL Developer resumes] Image_89.png\n",
            "Processing 144/12646: [ETL Developer resumes] Image_29.jpg\n",
            "Processing 145/12646: [ETL Developer resumes] Image_50.jpg\n",
            "Processing 146/12646: [ETL Developer resumes] Image_91.png\n",
            "Processing 147/12646: [ETL Developer resumes] Image_14.png\n",
            "Processing 148/12646: [ETL Developer resumes] Image_31.jpg\n",
            "Processing 149/12646: [ETL Developer resumes] Image_55.png\n",
            "Processing 150/12646: [ETL Developer resumes] Image_17.jpg\n",
            "Processing 151/12646: [ETL Developer resumes] Image_56.png\n",
            "Processing 152/12646: [ETL Developer resumes] Image_73.png\n",
            "Processing 153/12646: [ETL Developer resumes] Image_16.jpg\n",
            "Processing 154/12646: [ETL Developer resumes] Image_66.png\n",
            "Processing 155/12646: [ETL Developer resumes] Image_92.png\n",
            "Processing 156/12646: [ETL Developer resumes] Image_22.jpg\n",
            "Processing 157/12646: [ETL Developer resumes] Image_94.jpg\n",
            "Processing 158/12646: [ETL Developer resumes] Image_64.jpg\n",
            "Processing 159/12646: [ETL Developer resumes] Image_5.jpg\n",
            "Processing 160/12646: [ETL Developer resumes] Image_53.jpg\n",
            "Processing 161/12646: [ETL Developer resumes] Image_86.png\n",
            "Processing 162/12646: [ETL Developer resumes] Image_76.png\n",
            "Processing 163/12646: [ETL Developer resumes] Image_75.png\n",
            "Processing 164/12646: [ETL Developer resumes] Image_8.jpg\n",
            "Processing 165/12646: [ETL Developer resumes] Image_32.png\n",
            "Processing 166/12646: [ETL Developer resumes] Image_94.png\n",
            "Processing 167/12646: [ETL Developer resumes] Image_59.jpg\n",
            "Processing 168/12646: [ETL Developer resumes] Image_96.jpg\n",
            "Processing 169/12646: [Java Developer resumes] Image_43.png\n",
            "Processing 170/12646: [Java Developer resumes] Image_41.png\n",
            "Processing 171/12646: [Java Developer resumes] Image_21.jpg\n",
            "Processing 172/12646: [Java Developer resumes] Image_80.png\n",
            "Processing 173/12646: [Java Developer resumes] Image_65.png\n",
            "Processing 174/12646: [Java Developer resumes] Image_45.png\n",
            "Processing 175/12646: [Java Developer resumes] Image_74.jpg\n",
            "Processing 176/12646: [Java Developer resumes] Image_52.png\n",
            "Processing 177/12646: [Java Developer resumes] Image_36.png\n",
            "Processing 178/12646: [Java Developer resumes] Image_34.png\n",
            "Processing 179/12646: [Java Developer resumes] Image_76.jpg\n",
            "Processing 180/12646: [Java Developer resumes] Image_20.jpg\n",
            "Processing 181/12646: [Java Developer resumes] Image_50.png\n",
            "Processing 182/12646: [Java Developer resumes] Image_47.jpg\n",
            "Processing 183/12646: [Java Developer resumes] Image_88.png\n",
            "Processing 184/12646: [Java Developer resumes] Image_41.jpg\n",
            "Processing 185/12646: [Java Developer resumes] Image_68.jpg\n",
            "Processing 186/12646: [Java Developer resumes] Image_82.jpg\n",
            "Processing 187/12646: [Java Developer resumes] Image_51.jpg\n",
            "Processing 188/12646: [Java Developer resumes] Image_47.png\n",
            "Processing 189/12646: [Java Developer resumes] Image_11.png\n",
            "Processing 190/12646: [Java Developer resumes] Image_4.jpg\n",
            "Processing 191/12646: [Java Developer resumes] Image_95.png\n",
            "Processing 192/12646: [Java Developer resumes] Image_44.jpg\n",
            "Processing 193/12646: [Java Developer resumes] Image_19.jpg\n",
            "Processing 194/12646: [Java Developer resumes] Image_40.jpg\n",
            "Processing 195/12646: [Java Developer resumes] Image_79.jpg\n",
            "Processing 196/12646: [Java Developer resumes] Image_42.png\n",
            "Processing 197/12646: [Java Developer resumes] Image_30.png\n",
            "Processing 198/12646: [Java Developer resumes] Image_89.jpg\n",
            "Processing 199/12646: [Java Developer resumes] Image_15.jpg\n",
            "Processing 200/12646: [Java Developer resumes] Image_26.png\n",
            "Processing 201/12646: [Java Developer resumes] Image_88.jpg\n",
            "Processing 202/12646: [Java Developer resumes] Image_13.jpg\n",
            "Processing 203/12646: [Java Developer resumes] Image_48.jpg\n",
            "Processing 204/12646: [Java Developer resumes] Image_49.jpg\n",
            "Processing 205/12646: [Java Developer resumes] Image_38.png\n",
            "Processing 206/12646: [Java Developer resumes] Image_73.jpg\n",
            "Processing 207/12646: [Java Developer resumes] Image_25.jpg\n",
            "Processing 208/12646: [Java Developer resumes] Image_27.png\n",
            "Processing 209/12646: [Java Developer resumes] Image_78.jpg\n",
            "Processing 210/12646: [Java Developer resumes] Image_90.png\n",
            "Processing 211/12646: [Java Developer resumes] Image_98.jpg\n",
            "Processing 212/12646: [Java Developer resumes] Image_77.jpg\n",
            "Processing 213/12646: [Java Developer resumes] Image_10.png\n",
            "Processing 214/12646: [Java Developer resumes] Image_2.png\n",
            "Processing 215/12646: [Java Developer resumes] Image_9.jpg\n",
            "Processing 216/12646: [Java Developer resumes] Image_36.jpg\n",
            "Processing 217/12646: [Java Developer resumes] Image_45.jpg\n",
            "Processing 218/12646: [Java Developer resumes] Image_57.jpg\n",
            "Processing 219/12646: [Java Developer resumes] Image_69.png\n",
            "Processing 220/12646: [Java Developer resumes] Image_89.png\n",
            "Processing 221/12646: [Java Developer resumes] Image_62.jpg\n",
            "Processing 222/12646: [Java Developer resumes] Image_32.jpg\n",
            "Processing 223/12646: [Java Developer resumes] Image_33.jpg\n",
            "Processing 224/12646: [Java Developer resumes] Image_61.jpg\n",
            "Processing 225/12646: [Java Developer resumes] Image_14.jpg\n",
            "Processing 226/12646: [Java Developer resumes] Image_56.png\n",
            "Processing 227/12646: [Java Developer resumes] Image_18.png\n",
            "Processing 228/12646: [Java Developer resumes] Image_55.jpg\n",
            "Processing 229/12646: [Java Developer resumes] Image_94.jpg\n",
            "Processing 230/12646: [Java Developer resumes] Image_64.jpg\n",
            "Processing 231/12646: [Java Developer resumes] Image_28.png\n",
            "Processing 232/12646: [Java Developer resumes] Image_46.jpg\n",
            "Processing 233/12646: [Java Developer resumes] Image_1.png\n",
            "Processing 234/12646: [Java Developer resumes] Image_44.png\n",
            "Processing 235/12646: [Java Developer resumes] Image_5.jpg\n",
            "Processing 236/12646: [Java Developer resumes] Image_46.png\n",
            "Processing 237/12646: [Java Developer resumes] Image_38.jpg\n",
            "Processing 238/12646: [Java Developer resumes] Image_98.png\n",
            "Processing 239/12646: [Java Developer resumes] Image_86.png\n",
            "Processing 240/12646: [Java Developer resumes] Image_76.png\n",
            "Processing 241/12646: [Java Developer resumes] Image_7.jpg\n",
            "Processing 242/12646: [Java Developer resumes] Image_75.png\n",
            "Processing 243/12646: [Java Developer resumes] Image_3.jpg\n",
            "Processing 244/12646: [Java Developer resumes] Image_8.jpg\n",
            "Processing 245/12646: [Java Developer resumes] Image_83.jpg\n",
            "Processing 246/12646: [Java Developer resumes] Image_87.jpg\n",
            "Processing 247/12646: [Testing resumes] Image_96.png\n",
            "Processing 248/12646: [Testing resumes] Image_63.png\n",
            "Processing 249/12646: [Testing resumes] Image_80.png\n",
            "Processing 250/12646: [Testing resumes] Image_65.png\n",
            "Processing 251/12646: [Testing resumes] Image_1.jpg\n",
            "Processing 252/12646: [Testing resumes] Image_74.jpg\n",
            "Processing 253/12646: [Testing resumes] Image_24.png\n",
            "Processing 254/12646: [Testing resumes] Image_67.png\n",
            "Processing 255/12646: [Testing resumes] Image_81.png\n",
            "Processing 256/12646: [Testing resumes] Image_47.jpg\n",
            "Processing 257/12646: [Testing resumes] Image_58.jpg\n",
            "Processing 258/12646: [Testing resumes] Image_35.png\n",
            "Processing 259/12646: [Testing resumes] Image_93.png\n",
            "Processing 260/12646: [Testing resumes] Image_80.jpg\n",
            "Processing 261/12646: [Testing resumes] Image_82.jpg\n",
            "Processing 262/12646: [Testing resumes] Image_51.jpg\n",
            "Processing 263/12646: [Testing resumes] Image_11.png\n",
            "Processing 264/12646: [Testing resumes] Image_4.jpg\n",
            "Processing 265/12646: [Testing resumes] Image_95.png\n",
            "Processing 266/12646: [Testing resumes] Image_82.png\n",
            "Processing 267/12646: [Testing resumes] Image_44.jpg\n",
            "Processing 268/12646: [Testing resumes] Image_12.jpg\n",
            "Processing 269/12646: [Testing resumes] Image_40.jpg\n",
            "Processing 270/12646: [Testing resumes] Image_70.png\n",
            "Processing 271/12646: [Testing resumes] Image_30.jpg\n",
            "Processing 272/12646: [Testing resumes] Image_15.jpg\n",
            "Processing 273/12646: [Testing resumes] Image_26.png\n",
            "Processing 274/12646: [Testing resumes] Image_88.jpg\n",
            "Processing 275/12646: [Testing resumes] Image_10.jpg\n",
            "Processing 276/12646: [Testing resumes] Image_48.jpg\n",
            "Processing 277/12646: [Testing resumes] Image_71.jpg\n",
            "Processing 278/12646: [Testing resumes] Image_81.jpg\n",
            "Processing 279/12646: [Testing resumes] Image_73.jpg\n",
            "Processing 280/12646: [Testing resumes] Image_25.jpg\n",
            "Processing 281/12646: [Testing resumes] Image_72.png\n",
            "Processing 282/12646: [Testing resumes] Image_22.png\n",
            "Processing 283/12646: [Testing resumes] Image_91.jpg\n",
            "Processing 284/12646: [Testing resumes] Image_98.jpg\n",
            "Processing 285/12646: [Testing resumes] Image_68.png\n",
            "Processing 286/12646: [Testing resumes] Image_27.jpg\n",
            "Processing 287/12646: [Testing resumes] Image_9.jpg\n",
            "Processing 288/12646: [Testing resumes] Image_36.jpg\n",
            "Processing 289/12646: [Testing resumes] Image_45.jpg\n",
            "Processing 290/12646: [Testing resumes] Image_69.png\n",
            "Processing 291/12646: [Testing resumes] Image_89.png\n",
            "Processing 292/12646: [Testing resumes] Image_29.jpg\n",
            "Processing 293/12646: [Testing resumes] Image_50.jpg\n",
            "Processing 294/12646: [Testing resumes] Image_62.jpg\n",
            "Processing 295/12646: [Testing resumes] Image_91.png\n",
            "Processing 296/12646: [Testing resumes] Image_33.jpg\n",
            "Processing 297/12646: [Testing resumes] Image_66.jpg\n",
            "Processing 298/12646: [Testing resumes] Image_31.jpg\n",
            "Processing 299/12646: [Testing resumes] Image_92.jpg\n",
            "Processing 300/12646: [Testing resumes] Image_61.jpg\n",
            "Processing 301/12646: [Testing resumes] Image_17.jpg\n",
            "Processing 302/12646: [Testing resumes] Image_66.png\n",
            "Processing 303/12646: [Testing resumes] Image_92.png\n",
            "Processing 304/12646: [Testing resumes] Image_85.jpg\n",
            "Processing 305/12646: [Testing resumes] Image_37.jpg\n",
            "Processing 306/12646: [Testing resumes] Image_78.png\n",
            "Processing 307/12646: [Testing resumes] Image_64.jpg\n",
            "Processing 308/12646: [Testing resumes] Image_46.jpg\n",
            "Processing 309/12646: [Testing resumes] Image_5.jpg\n",
            "Processing 310/12646: [Testing resumes] Image_84.jpg\n",
            "Processing 311/12646: [Testing resumes] Image_83.png\n",
            "Processing 312/12646: [Testing resumes] Image_38.jpg\n",
            "Processing 313/12646: [Testing resumes] Image_98.png\n",
            "Processing 314/12646: [Testing resumes] Image_3.jpg\n",
            "Processing 315/12646: [Testing resumes] Image_77.png\n",
            "Processing 316/12646: [Testing resumes] Image_87.jpg\n",
            "Processing 317/12646: [Testing resumes] Image_97.png\n",
            "Processing 318/12646: [Testing resumes] Image_28.jpg\n",
            "Processing 319/12646: [Testing resumes] Image_56.jpg\n",
            "Processing 320/12646: [Testing resumes] Image_96.jpg\n",
            "Processing 321/12646: [Testing resumes] Image_18.jpg\n",
            "Processing 322/12646: [Testing resumes] Image_20.png\n",
            "Processing 323/12646: [Architects resumes] Image_41.png\n",
            "Processing 324/12646: [Architects resumes] Image_6.png\n",
            "Processing 325/12646: [Architects resumes] Image_21.jpg\n",
            "Processing 326/12646: [Architects resumes] Image_80.png\n",
            "Processing 327/12646: [Architects resumes] Image_53.png\n",
            "Processing 328/12646: [Architects resumes] Image_64.png\n",
            "Processing 329/12646: [Architects resumes] Image_72.jpg\n",
            "Processing 330/12646: [Architects resumes] Image_99.png\n",
            "Processing 331/12646: [Architects resumes] Image_76.jpg\n",
            "Processing 332/12646: [Architects resumes] Image_57.png\n",
            "Processing 333/12646: [Architects resumes] Image_26.jpg\n",
            "Processing 334/12646: [Architects resumes] Image_100.jpg\n",
            "Processing 335/12646: [Architects resumes] Image_58.jpg\n",
            "Processing 336/12646: [Architects resumes] Image_82.jpg\n",
            "Processing 337/12646: [Architects resumes] Image_4.jpg\n",
            "Processing 338/12646: [Architects resumes] Image_39.png\n",
            "Processing 339/12646: [Architects resumes] Image_44.jpg\n",
            "Processing 340/12646: [Architects resumes] Image_19.jpg\n",
            "Processing 341/12646: [Architects resumes] Image_71.png\n",
            "Processing 342/12646: [Architects resumes] Image_52.jpg\n",
            "Processing 343/12646: [Architects resumes] Image_12.jpg\n",
            "Processing 344/12646: [Architects resumes] Image_70.png\n",
            "Processing 345/12646: [Architects resumes] Image_30.jpg\n",
            "Processing 346/12646: [Architects resumes] Image_15.jpg\n",
            "Processing 347/12646: [Architects resumes] Image_88.jpg\n",
            "Processing 348/12646: [Architects resumes] Image_13.jpg\n",
            "Processing 349/12646: [Architects resumes] Image_48.jpg\n",
            "Processing 350/12646: [Architects resumes] Image_69.jpg\n",
            "Processing 351/12646: [Architects resumes] Image_81.jpg\n",
            "Processing 352/12646: [Architects resumes] Image_73.jpg\n",
            "Processing 353/12646: [Architects resumes] Image_78.jpg\n",
            "Processing 354/12646: [Architects resumes] Image_22.png\n",
            "Processing 355/12646: [Architects resumes] Image_91.jpg\n",
            "Processing 356/12646: [Architects resumes] Image_77.jpg\n",
            "Processing 357/12646: [Architects resumes] Image_27.jpg\n",
            "Processing 358/12646: [Architects resumes] Image_10.png\n",
            "Processing 359/12646: [Architects resumes] Image_9.jpg\n",
            "Processing 360/12646: [Architects resumes] Image_36.jpg\n",
            "Processing 361/12646: [Architects resumes] Image_29.jpg\n",
            "Processing 362/12646: [Architects resumes] Image_50.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-238112870.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;31m#   - ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m     stats = process_nested_folders(\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mcsv_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cv_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-238112870.py\u001b[0m in \u001b[0;36mprocess_nested_folders\u001b[0;34m(root_dir, csv_path, overwrite, save_processed, show_details)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Process the CV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_cv_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_processed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;31m# Add category to results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-238112870.py\u001b[0m in \u001b[0;36mprocess_cv_image\u001b[0;34m(file_path, save_processed, output_dir, show_details)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step 5: Extracting text...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mextracted_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mdetailed_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_with_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_details\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-238112870.py\u001b[0m in \u001b[0;36mextract_text_with_details\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Get detailed OCR data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mtext_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_data\u001b[0;34m(image, lang, config, nice, output_type, timeout, pandas_config)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         Output.DATAFRAME: lambda: get_pandas_output(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mpandas_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         ),\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     }[output_type]()\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    350\u001b[0m         }\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         return _read_output(\n\u001b[1;32m    354\u001b[0m             \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import cv2 as cv # image processing\n",
        "import numpy as np # for math calculations\n",
        "from PIL import Image # opening/verifying images\n",
        "import pytesseract # OCR engine\n",
        "import os # check if file exists, create directories\n",
        "from pathlib import Path # handle file paths\n",
        "import csv # reading/writing CSV files\n",
        "import fitz  # PyMuPDF for PDF handling\n",
        "from docx import Document  # python-docx for Word documents\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "# Function to validate image file\n",
        "def is_valid_image(file_path):\n",
        "    # Check if file-path exists\n",
        "    if not os.path.exists(file_path):\n",
        "        # print(f\"Error: File not found - {file_path}\")\n",
        "        return False\n",
        "\n",
        "    # Check for valid image extensions\n",
        "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.pdf', '.docx', '.doc'}\n",
        "    file_ext = Path(file_path).suffix.lower()\n",
        "\n",
        "    # Check file extension\n",
        "    if file_ext not in valid_extensions:\n",
        "        print(f\"Error: Invalid file extension - {file_ext}\")\n",
        "        return False\n",
        "\n",
        "    # If PDF, verify it's a valid PDF\n",
        "    if file_ext == '.pdf':\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            doc.close()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            # print(f\"Error: Invalid PDF file - {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    # If DOCX, verify it's a valid DOCX\n",
        "    if file_ext in ['.docx', '.doc']:\n",
        "        try:\n",
        "            doc = Document(file_path)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            # print(f\"Error: Invalid DOCX file - {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    # Try to load the image and verify\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            # verify() checks for corruption\n",
        "            img.verify()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # print(f\"Error: Cannot open image - {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# calculate text density in the image (Purpose: How much text vs empty space in the image?)\n",
        "def calculate_text_density(gray):\n",
        "    # Converts image to black & white (text = white, background = black)\n",
        "    _, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
        "\n",
        "    # Calculate percentage of text pixels (Counts white pixels (text) vs total pixels)\n",
        "    text_pixels = np.sum(binary == 255)\n",
        "    total_pixels = binary.size\n",
        "    text_density = (text_pixels / total_pixels) * 100\n",
        "    return round(text_density, 2)\n",
        "\n",
        "\n",
        "# calculate noise level in the image (Purpose: How grainy/dirty is the image?)\n",
        "def calculate_noise_level(gray, kernel_size=5):\n",
        "    # Apply median filter to remove noise\n",
        "    median_filtered = cv.medianBlur(gray, kernel_size)\n",
        "\n",
        "    # Difference between original and filtered = noise\n",
        "    noise = cv.absdiff(gray, median_filtered)\n",
        "    noise_level = np.mean(noise)\n",
        "\n",
        "    return round(noise_level, 2)\n",
        "\n",
        "\n",
        "def calculate_skew_angle(gray):\n",
        "    edges = cv.Canny(gray, 50, 150, apertureSize=3)\n",
        "    lines = cv.HoughLines(edges, 1, np.pi / 180, 200)\n",
        "\n",
        "    if lines is not None and len(lines) > 0:\n",
        "        angles = []\n",
        "        for rho, theta in lines[:, 0]:\n",
        "            angle = (theta * 180 / np.pi) - 90\n",
        "            angles.append(angle)\n",
        "        skew = abs(np.median(angles))\n",
        "        return round(skew, 2)\n",
        "\n",
        "    return 0.0\n",
        "\n",
        "\n",
        "# Purpose: Is the background clean or has shadows/stains?\n",
        "def calculate_background_uniformity(gray):\n",
        "    # Heavy blur to get background\n",
        "    background = cv.GaussianBlur(gray, (51, 51), 0)\n",
        "\n",
        "    # Check variation in background\n",
        "    uniformity = np.std(background)\n",
        "\n",
        "    return round(uniformity, 2)\n",
        "\n",
        "\n",
        "# Purpose: Does the image have normal document proportions?\n",
        "def check_aspect_ratio(image):\n",
        "    height, width = image.shape[:2]\n",
        "    aspect_ratio = width / height\n",
        "\n",
        "    # Standard paper ratios: A4=1.414\n",
        "    # Allow range: 0.65 (portrait) to 1.7 (wide portrait)\n",
        "    is_normal = 0.65 < aspect_ratio < 1.7\n",
        "\n",
        "    return round(aspect_ratio, 2), is_normal\n",
        "\n",
        "\n",
        "# Purpose: The MAIN quality checker - combines all tests!\n",
        "def calculate_image_quality(image):\n",
        "    # Convert to grayscale if needed\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    # Basic metrics\n",
        "    laplacian_var = cv.Laplacian(gray, cv.CV_64F).var() # Sharpness (Laplacian variance), Measures how sharp/blurry, and the image is High value = sharp, Low value = blurry\n",
        "    brightness = np.mean(gray) # Brightness (Mean pixel value), Average brightness of the image, Higher value = brighter image\n",
        "    contrast = np.std(gray) # Contrast (Standard deviation of pixel values), Measures difference between light and dark areas,( High = easy to read, Low = washed out )\n",
        "\n",
        "    # Resolution\n",
        "    height, width = gray.shape\n",
        "    resolution = width * height\n",
        "\n",
        "    # Advanced metrics\n",
        "    text_density = calculate_text_density(gray)\n",
        "    noise_level = calculate_noise_level(gray)\n",
        "    skew_angle = calculate_skew_angle(gray)\n",
        "    background_uniformity = calculate_background_uniformity(gray)\n",
        "    aspect_ratio, is_normal_aspect = check_aspect_ratio(image)\n",
        "\n",
        "    # Determine if image needs preprocessing\n",
        "    needs_processing = False\n",
        "    reasons = []\n",
        "\n",
        "    # Check basic quality\n",
        "    if laplacian_var < 100:  # Blurry image\n",
        "        needs_processing = True\n",
        "        reasons.append(\"low_sharpness\")\n",
        "\n",
        "    if brightness < 50 or brightness > 200:  # Too dark or too bright\n",
        "        needs_processing = True\n",
        "        reasons.append(\"poor_brightness\")\n",
        "\n",
        "    if contrast < 30:  # Low contrast == washed out\n",
        "        needs_processing = True\n",
        "        reasons.append(\"low_contrast\")\n",
        "\n",
        "    if resolution < 500000:  # Low resolution\n",
        "        needs_processing = True\n",
        "        reasons.append(\"low_resolution\")\n",
        "\n",
        "    # Check advanced quality\n",
        "    if text_density < 8 or text_density > 50:  # Too sparse or too dense\n",
        "        needs_processing = True\n",
        "        reasons.append(\"abnormal_text_density\")\n",
        "\n",
        "    if noise_level > 10:  # Noisy image\n",
        "        needs_processing = True\n",
        "        reasons.append(\"high_noise\")\n",
        "\n",
        "    if skew_angle > 2:  # Tilted document\n",
        "        needs_processing = True\n",
        "        reasons.append(\"skewed_document\")\n",
        "\n",
        "    if background_uniformity > 25:  # Uneven background\n",
        "        needs_processing = True\n",
        "        reasons.append(\"non_uniform_background\")\n",
        "\n",
        "    if not is_normal_aspect:  # Abnormal proportions\n",
        "        needs_processing = True\n",
        "        reasons.append(\"abnormal_aspect_ratio\")\n",
        "\n",
        "    # Calculate overall quality score\n",
        "    quality_score = calculate_quality_score(\n",
        "        laplacian_var, brightness, contrast, resolution,\n",
        "        text_density, noise_level, skew_angle, background_uniformity\n",
        "    )\n",
        "\n",
        "    quality_metrics = {\n",
        "        # Basic metrics\n",
        "        'sharpness': round(laplacian_var, 2),\n",
        "        'brightness': round(brightness, 2),\n",
        "        'contrast': round(contrast, 2),\n",
        "        'resolution': resolution,\n",
        "\n",
        "        # Advanced metrics\n",
        "        'text_density': text_density,\n",
        "        'noise_level': noise_level,\n",
        "        'skew_angle': skew_angle,\n",
        "        'background_uniformity': background_uniformity,\n",
        "        'aspect_ratio': aspect_ratio,\n",
        "        'is_normal_aspect': is_normal_aspect,\n",
        "\n",
        "        # Overall assessment\n",
        "        'needs_processing': needs_processing,\n",
        "        'reasons': reasons,\n",
        "        'quality_score': quality_score\n",
        "    }\n",
        "\n",
        "    return quality_metrics\n",
        "\n",
        "\n",
        "# Purpose: Give the image a grade from 0-100\n",
        "def calculate_quality_score(sharpness, brightness, contrast, resolution,\n",
        "                            text_density=None, noise_level=None, skew_angle=None,\n",
        "                            background_uniformity=None):\n",
        "    # Basic metrics (70 points total)\n",
        "    sharpness_score = min(sharpness / 500, 1.0) * 25  # Max 25 points\n",
        "\n",
        "    # Brightness score (optimal range 80-180)\n",
        "    brightness_diff = abs(brightness - 130)\n",
        "    brightness_score = max(0, (1 - brightness_diff / 130)) * 20  # Max 20 points\n",
        "\n",
        "    # Contrast score\n",
        "    contrast_score = min(contrast / 100, 1.0) * 15  # Max 15 points\n",
        "\n",
        "    # Resolution score\n",
        "    resolution_score = min(resolution / 2000000, 1.0) * 10  # Max 10 points\n",
        "\n",
        "    total_score = sharpness_score + brightness_score + contrast_score + resolution_score\n",
        "\n",
        "    # Advanced metrics (30 points total) - only if provided\n",
        "    if text_density is not None:\n",
        "        # Optimal text density: 15-35%\n",
        "        if 15 <= text_density <= 35:\n",
        "            density_score = 10\n",
        "        elif 10 <= text_density < 15 or 35 < text_density <= 45:\n",
        "            density_score = 5\n",
        "        else:\n",
        "            density_score = 0\n",
        "        total_score += density_score\n",
        "\n",
        "    if noise_level is not None:\n",
        "        # Lower noise is better\n",
        "        noise_score = max(0, (1 - noise_level / 20)) * 8  # Max 8 points\n",
        "        total_score += noise_score\n",
        "\n",
        "    if skew_angle is not None:\n",
        "        # Less skew is better\n",
        "        skew_score = max(0, (1 - skew_angle / 10)) * 7  # Max 7 points\n",
        "        total_score += skew_score\n",
        "\n",
        "    if background_uniformity is not None:\n",
        "        # More uniform is better\n",
        "        uniformity_score = max(0, (1 - background_uniformity / 50)) * 5  # Max 5 points\n",
        "        total_score += uniformity_score\n",
        "\n",
        "    return round(total_score, 2)\n",
        "\n",
        "\n",
        "# Purpose: Fix images that are too dark or too bright\n",
        "def enhance_brightness_contrast(image):\n",
        "    # Convert to LAB color space\n",
        "    if len(image.shape) == 3:\n",
        "        lab = cv.cvtColor(image, cv.COLOR_BGR2LAB)\n",
        "        l, a, b = cv.split(lab)\n",
        "    else:\n",
        "        l = image\n",
        "\n",
        "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    clahe = cv.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)) # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    enhanced_l = clahe.apply(l)\n",
        "\n",
        "    if len(image.shape) == 3:\n",
        "        enhanced_lab = cv.merge([enhanced_l, a, b])\n",
        "        enhanced = cv.cvtColor(enhanced_lab, cv.COLOR_LAB2BGR)\n",
        "    else:\n",
        "        enhanced = enhanced_l\n",
        "\n",
        "    return enhanced\n",
        "\n",
        "\n",
        "# Purpose: Reduce noise/graininess from the image\n",
        "def denoise_image(image):\n",
        "    if len(image.shape) == 3:\n",
        "        denoised = cv.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "    else:\n",
        "        denoised = cv.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
        "\n",
        "    return denoised\n",
        "\n",
        "\n",
        "# Purpose: Make blurry text sharper\n",
        "def sharpen_image(image):\n",
        "    kernel = np.array([ [-1, -1, -1],\n",
        "                        [-1,  9, -1],\n",
        "                        [-1, -1, -1]])\n",
        "    sharpened = cv.filter2D(image, -1, kernel)\n",
        "    return sharpened\n",
        "\n",
        "\n",
        "def binarize_image(image):\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    # Apply Otsu's thresholding\n",
        "    _, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU) # Text becomes pure black, background becomes pure white\n",
        "\n",
        "    return binary\n",
        "\n",
        "\n",
        "# Purpose: Rotate tilted documents to be straight\n",
        "def deskew_image(image):\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    # Detect edges\n",
        "    edges = cv.Canny(gray, 50, 150, apertureSize=3)\n",
        "\n",
        "    # Detect lines using Hough transform\n",
        "    lines = cv.HoughLines(edges, 1, np.pi / 180, 200)\n",
        "\n",
        "    if lines is not None and len(lines) > 0:\n",
        "        # Calculate median angle\n",
        "        angles = []\n",
        "        for rho, theta in lines[:, 0]:\n",
        "            angle = (theta * 180 / np.pi) - 90\n",
        "            angles.append(angle)\n",
        "\n",
        "        median_angle = np.median(angles)\n",
        "\n",
        "        # Only rotate if angle is significant\n",
        "        if abs(median_angle) > 0.5:\n",
        "            height, width = image.shape[:2]\n",
        "            center = (width // 2, height // 2)\n",
        "            rotation_matrix = cv.getRotationMatrix2D(center, median_angle, 1.0)\n",
        "            rotated = cv.warpAffine(image, rotation_matrix, (width, height),\n",
        "                                    flags=cv.INTER_CUBIC,\n",
        "                                    borderMode=cv.BORDER_REPLICATE)\n",
        "            return rotated\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# Purpose: Make small images bigger for better OCR\n",
        "def upscale_image(image, scale_factor=2):\n",
        "    height, width = image.shape[:2]\n",
        "    new_dimensions = (width * scale_factor, height * scale_factor)\n",
        "    upscaled = cv.resize(image, new_dimensions, interpolation=cv.INTER_CUBIC)\n",
        "    return upscaled\n",
        "\n",
        "\n",
        "def preprocess_image(image, quality_metrics, show_details=False):\n",
        "    processed = image.copy()\n",
        "    reasons = quality_metrics['reasons']\n",
        "\n",
        "    if not reasons:\n",
        "        if show_details:\n",
        "            print(\"Image quality is good, applying minimal processing...\")\n",
        "    else:\n",
        "        if show_details:\n",
        "            print(f\"Applying preprocessing for: {', '.join(reasons)}\")\n",
        "\n",
        "    # Upscale if low resolution\n",
        "    if 'low_resolution' in reasons:\n",
        "        if show_details:\n",
        "            print(\"  - Upscaling image...\")\n",
        "        processed = upscale_image(processed, scale_factor=2)\n",
        "\n",
        "    # Deskew if needed (or if skew detected)\n",
        "    if 'skewed_document' in reasons:\n",
        "        if show_details:\n",
        "            print(\"  - Deskewing image...\")\n",
        "        processed = deskew_image(processed)\n",
        "\n",
        "    # Denoise if noisy\n",
        "    if 'high_noise' in reasons:\n",
        "        if show_details:\n",
        "            print(\"  - Denoising image...\")\n",
        "        processed = denoise_image(processed)\n",
        "\n",
        "    # Enhance brightness and contrast if needed\n",
        "    if 'poor_brightness' in reasons or 'low_contrast' in reasons or 'non_uniform_background' in reasons:\n",
        "        if show_details:\n",
        "            print(\"  - Enhancing brightness and contrast...\")\n",
        "        processed = enhance_brightness_contrast(processed)\n",
        "\n",
        "    # Sharpen if blurry\n",
        "    if 'low_sharpness' in reasons:\n",
        "        if show_details:\n",
        "            print(\"  - Sharpening image...\")\n",
        "        processed = sharpen_image(processed)\n",
        "\n",
        "    # Binarize for better OCR (always done at the end)\n",
        "    if show_details:\n",
        "        print(\"  - Binarizing image...\")\n",
        "    processed = binarize_image(processed)\n",
        "\n",
        "    return processed\n",
        "\n",
        "\n",
        "# Purpose: Extract text(paragraphs & tables) from DOCX files\n",
        "def extract_text_from_docx(docx_path, show_details=False):\n",
        "    try:\n",
        "        if show_details:\n",
        "            print(\"  - Extracting text from DOCX using python-docx...\")\n",
        "\n",
        "        # Open DOCX\n",
        "        doc = Document(docx_path)\n",
        "\n",
        "        # Extract text from all paragraphs\n",
        "        full_text = \"\"\n",
        "        paragraph_count = 0\n",
        "\n",
        "        for paragraph in doc.paragraphs:\n",
        "            if paragraph.text.strip():  # Only add non-empty paragraphs\n",
        "                full_text += paragraph.text + \"\\n\"\n",
        "                paragraph_count += 1\n",
        "\n",
        "        # Also extract text from tables\n",
        "        table_count = len(doc.tables)\n",
        "        for table in doc.tables:\n",
        "            for row in table.rows:\n",
        "                for cell in row.cells:\n",
        "                    if cell.text.strip():\n",
        "                        full_text += cell.text + \" \"\n",
        "            full_text += \"\\n\"\n",
        "\n",
        "        # Clean up text\n",
        "        full_text = full_text.strip()\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"  - Extracted text from {paragraph_count} paragraph(s)\")\n",
        "            if table_count > 0:\n",
        "                print(f\"  - Extracted text from {table_count} table(s)\")\n",
        "            print(f\"  - Total characters: {len(full_text)}\")\n",
        "\n",
        "        return {\n",
        "            'text': full_text,\n",
        "            'paragraph_count': paragraph_count,\n",
        "            'table_count': table_count,\n",
        "            'success': True\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        if show_details:\n",
        "            print(f\"  - Error extracting from DOCX: {str(e)}\")\n",
        "        return {\n",
        "            'text': '',\n",
        "            'paragraph_count': 0,\n",
        "            'table_count': 0,\n",
        "            'success': False,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "# Purpose: Check if file is a DOCX or DOC\n",
        "def is_docx_file(file_path):\n",
        "    return Path(file_path).suffix.lower() in ['.docx', '.doc']\n",
        "\n",
        "\n",
        "# Purpose: Extract text from PDF files\n",
        "def extract_text_from_pdf(pdf_path, show_details=False):\n",
        "    try:\n",
        "        if show_details:\n",
        "            print(\"  - Extracting text from PDF using PyMuPDF...\")\n",
        "\n",
        "        # Open PDF\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        # Extract text from all pages\n",
        "        full_text = \"\"\n",
        "        page_count = len(doc)\n",
        "\n",
        "        for page_num in range(page_count):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text()\n",
        "            full_text += text + \"\\n\"\n",
        "\n",
        "        doc.close()\n",
        "\n",
        "        # Clean up text\n",
        "        full_text = full_text.strip()\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"  - Extracted text from {page_count} page(s)\")\n",
        "            print(f\"  - Total characters: {len(full_text)}\")\n",
        "\n",
        "        return {\n",
        "            'text': full_text,\n",
        "            'page_count': page_count,\n",
        "            'success': True\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        if show_details:\n",
        "            print(f\"  - Error extracting from PDF: {str(e)}\")\n",
        "        return {\n",
        "            'text': '',\n",
        "            'page_count': 0,\n",
        "            'success': False,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "# Purpose: Check if file is a PDF\n",
        "def is_pdf_file(file_path):\n",
        "    return Path(file_path).suffix.lower() == '.pdf'\n",
        "\n",
        "\n",
        "\n",
        "def extract_text_from_image(image, config='--oem 3 --psm 6'):\n",
        "    try:\n",
        "        text = pytesseract.image_to_string(image, config=config)\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        # print(f\"Error during text extraction: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Purpose: Extract text along with confidence scores and bounding boxes\n",
        "def extract_text_with_details(image):\n",
        "    try:\n",
        "        # Get detailed OCR data\n",
        "        data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
        "\n",
        "        text_blocks = []\n",
        "        n_boxes = len(data['text'])\n",
        "\n",
        "        # Collect text blocks with confidence and bounding boxes\n",
        "        for i in range(n_boxes):\n",
        "            if int(data['conf'][i]) > 0:  # Only include confident detections\n",
        "                text_blocks.append({\n",
        "                    'text': data['text'][i],\n",
        "                    'confidence': data['conf'][i],\n",
        "                    'bbox': (data['left'][i], data['top'][i],\n",
        "                            data['width'][i], data['height'][i])\n",
        "                })\n",
        "\n",
        "        full_text = ' '.join([block['text'] for block in text_blocks if block['text'].strip()])\n",
        "        avg_confidence = np.mean([block['confidence'] for block in text_blocks]) if text_blocks else 0\n",
        "\n",
        "        return {\n",
        "            'text': full_text,\n",
        "            'average_confidence': round(avg_confidence, 2),\n",
        "            'blocks': text_blocks\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # print(f\"Error during detailed extraction: {str(e)}\")\n",
        "        return {'text': '', 'average_confidence': 0, 'blocks': []}\n",
        "\n",
        "\n",
        "# Purpose: The COMPLETE pipeline - from image to text!\n",
        "def process_cv_image(file_path, save_processed=False, output_dir='processed_images', show_details=False):\n",
        "    if show_details:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing CV: {file_path}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Step 1: Validate file\n",
        "    if show_details:\n",
        "        print(\"Step 1: Validating file...\")\n",
        "    if not is_valid_image(file_path):\n",
        "        return {'error': 'Invalid file', 'file_path': file_path}\n",
        "    if show_details:\n",
        "        print(\"file is valid\\n\")\n",
        "\n",
        "    # Check if file is DOCX\n",
        "    if is_docx_file(file_path):\n",
        "        if show_details:\n",
        "            print(\"Step 2: Detected DOCX file\")\n",
        "            print(\"Step 3: Extracting text from DOCX...\\n\")\n",
        "\n",
        "        # Extract text from DOCX\n",
        "        docx_results = extract_text_from_docx(file_path, show_details=show_details)\n",
        "\n",
        "        if not docx_results['success']:\n",
        "            return {\n",
        "                'error': 'Failed to extract from DOCX',\n",
        "                'file_path': file_path,\n",
        "                'details': docx_results.get('error', 'Unknown error')\n",
        "            }\n",
        "\n",
        "        extracted_text = docx_results['text']\n",
        "\n",
        "        if show_details:\n",
        "            if extracted_text:\n",
        "                print(f\"Text extracted successfully ({len(extracted_text)} characters)\")\n",
        "                print(f\"  Paragraphs: {docx_results['paragraph_count']}\")\n",
        "                print(f\"  Tables: {docx_results['table_count']}\\n\")\n",
        "            else:\n",
        "                print(\"No text extracted (DOCX might be empty)\\n\")\n",
        "\n",
        "        # Prepare results for DOCX\n",
        "        results = {\n",
        "            'file_path': file_path,\n",
        "            'file_type': 'DOCX',\n",
        "            'paragraph_count': docx_results['paragraph_count'],\n",
        "            'table_count': docx_results['table_count'],\n",
        "            'quality_metrics': {\n",
        "                'quality_score': 100,  # DOCX files are high quality\n",
        "                'extraction_method': 'direct_text'\n",
        "            },\n",
        "            'preprocessing_applied': False,\n",
        "            'extracted_text': extracted_text,\n",
        "            'text_length': len(extracted_text),\n",
        "            'average_confidence': 100.0,  # Direct text extraction = 100% confidence\n",
        "            'word_count': len(extracted_text.split())\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    # Check if file is PDF\n",
        "    if is_pdf_file(file_path):\n",
        "        if show_details:\n",
        "            print(\"Step 2: Detected PDF file\")\n",
        "            print(\"Step 3: Extracting text from PDF...\\n\")\n",
        "\n",
        "        # Extract text directly from PDF\n",
        "        pdf_results = extract_text_from_pdf(file_path, show_details=show_details)\n",
        "\n",
        "        if not pdf_results['success']:\n",
        "            return {\n",
        "                'error': 'Failed to extract from PDF',\n",
        "                'file_path': file_path,\n",
        "                'details': pdf_results.get('error', 'Unknown error')\n",
        "            }\n",
        "\n",
        "        extracted_text = pdf_results['text']\n",
        "\n",
        "        if show_details:\n",
        "            if extracted_text:\n",
        "                print(f\"Text extracted successfully ({len(extracted_text)} characters)\")\n",
        "                print(f\"  Pages processed: {pdf_results['page_count']}\\n\")\n",
        "            else:\n",
        "                print(\"No text extracted (PDF might be image-based)\\n\")\n",
        "\n",
        "        # Prepare results for PDF\n",
        "        results = {\n",
        "            'file_path': file_path,\n",
        "            'file_type': 'PDF',\n",
        "            'page_count': pdf_results['page_count'],\n",
        "            'quality_metrics': {\n",
        "                'quality_score': 100,  # PDFs with text are high quality\n",
        "                'extraction_method': 'direct_text'\n",
        "            },\n",
        "            'preprocessing_applied': False,\n",
        "            'extracted_text': extracted_text,\n",
        "            'text_length': len(extracted_text),\n",
        "            'average_confidence': 100.0,  # Direct text extraction = 100% confidence\n",
        "            'word_count': len(extracted_text.split())\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    # Step 2: Load image (if not PDF or DOCX, process as image)\n",
        "    if show_details:\n",
        "        print(\"Step 2: Loading image...\")\n",
        "    image = cv.imread(file_path)\n",
        "    if image is None:\n",
        "        return {'error': 'Failed to load image', 'file_path': file_path}\n",
        "    if show_details:\n",
        "        print(f\"Image loaded: {image.shape[1]}x{image.shape[0]} pixels\\n\")\n",
        "\n",
        "    # Step 3: Assess quality\n",
        "    if show_details:\n",
        "        print(\"Step 3: Assessing image quality...\")\n",
        "    quality_metrics = calculate_image_quality(image)\n",
        "    if show_details:\n",
        "        print(f\"  Basic Metrics:\")\n",
        "        print(f\"    Sharpness: {quality_metrics['sharpness']:.2f}\")\n",
        "        print(f\"    Brightness: {quality_metrics['brightness']:.2f}\")\n",
        "        print(f\"    Contrast: {quality_metrics['contrast']:.2f}\")\n",
        "        print(f\"    Resolution: {quality_metrics['resolution']} pixels\")\n",
        "        print(f\"  Advanced Metrics:\")\n",
        "        print(f\"    Text Density: {quality_metrics['text_density']:.2f}%\")\n",
        "        print(f\"    Noise Level: {quality_metrics['noise_level']:.2f}\")\n",
        "        print(f\"    Skew Angle: {quality_metrics['skew_angle']:.2f}°\")\n",
        "        print(f\"    Background Uniformity: {quality_metrics['background_uniformity']:.2f}\")\n",
        "        print(f\"    Aspect Ratio: {quality_metrics['aspect_ratio']} ({'Normal' if quality_metrics['is_normal_aspect'] else 'Abnormal'})\")\n",
        "        print(f\"  Overall Quality Score: {quality_metrics['quality_score']}/100\")\n",
        "        print(f\"  Needs Processing: {quality_metrics['needs_processing']}\")\n",
        "        if quality_metrics['reasons']:\n",
        "            print(f\"  Issues Found: {', '.join(quality_metrics['reasons'])}\")\n",
        "        print()\n",
        "\n",
        "    # Step 4: Preprocess if needed\n",
        "    if quality_metrics['needs_processing']:\n",
        "        if show_details:\n",
        "            print(\"Step 4: Preprocessing image (quality issues detected)...\")\n",
        "        processed_image = preprocess_image(image, quality_metrics, show_details=show_details)\n",
        "        if show_details:\n",
        "            print(\"✓ Preprocessing complete\\n\")\n",
        "    else:\n",
        "        if show_details:\n",
        "            print(\"Step 4: Skipping preprocessing (image quality is good)...\")\n",
        "        # Still apply basic binarization for better OCR\n",
        "        processed_image = binarize_image(image)\n",
        "        if show_details:\n",
        "            print(\"✓ Applied basic binarization\\n\")\n",
        "\n",
        "    # Step 6: Extract text\n",
        "    if show_details:\n",
        "        print(\"Step 5: Extracting text...\")\n",
        "    extracted_text = extract_text_from_image(processed_image)\n",
        "    detailed_results = extract_text_with_details(processed_image)\n",
        "\n",
        "    if show_details:\n",
        "        if extracted_text:\n",
        "            print(f\"Text extracted successfully ({len(extracted_text)} characters)\")\n",
        "            print(f\"  Average confidence: {detailed_results['average_confidence']:.2f}%\\n\")\n",
        "        else:\n",
        "            print(\"No text extracted\\n\")\n",
        "\n",
        "    # Prepare results\n",
        "    results = {\n",
        "        'file_path': file_path,\n",
        "        'quality_metrics': quality_metrics,\n",
        "        'preprocessing_applied': quality_metrics['needs_processing'],\n",
        "        'extracted_text': extracted_text,\n",
        "        'text_length': len(extracted_text),\n",
        "        'average_confidence': detailed_results['average_confidence'],\n",
        "        'word_count': len(extracted_text.split()),\n",
        "        'detailed_results': detailed_results\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Purpose: Save FULL results with all metadata\n",
        "def save_to_csv(results, csv_path='cv_dataset.csv', append=True):\n",
        "    try:\n",
        "        if 'error' in results:\n",
        "            return False\n",
        "\n",
        "        # Prepare row data with category\n",
        "        row_data = {\n",
        "            'filename': Path(results['file_path']).name,\n",
        "            'full_path': results['file_path'],\n",
        "            'file_type': results.get('file_type', 'Image'),\n",
        "            'category': results.get('category', 'unknown'),\n",
        "            'main_folder': results.get('main_folder', 'unknown'),\n",
        "            'subfolder': results.get('subfolder', 'unknown'),\n",
        "            'extracted_text': results['extracted_text'],\n",
        "            'quality_score': results.get('quality_metrics', {}).get('quality_score', 0),\n",
        "            'sharpness': results.get('quality_metrics', {}).get('sharpness', 0),\n",
        "            'brightness': results.get('quality_metrics', {}).get('brightness', 0),\n",
        "            'contrast': results.get('quality_metrics', {}).get('contrast', 0),\n",
        "            'resolution': results.get('quality_metrics', {}).get('resolution', 0),\n",
        "            'preprocessing_applied': results.get('preprocessing_applied', False),\n",
        "            'text_length': results['text_length'],\n",
        "            'word_count': results['word_count'],\n",
        "            'average_confidence': results.get('average_confidence', 0)\n",
        "        }\n",
        "\n",
        "        file_exists = os.path.exists(csv_path)\n",
        "        mode = 'a' if (append and file_exists) else 'w'\n",
        "\n",
        "        with open(csv_path, mode, newline='', encoding='utf-8') as csvfile:\n",
        "            fieldnames = list(row_data.keys())\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "            if not file_exists or not append:\n",
        "                writer.writeheader()\n",
        "\n",
        "            writer.writerow(row_data)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to CSV: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "# Purpose: Save minimal text data to CSV for model training\n",
        "def save_text_only_csv(results, csv_path='cv_text_dataset.csv', append=True):\n",
        "    try:\n",
        "        if 'error' in results:\n",
        "            return False\n",
        "\n",
        "        # Prepare minimal row data with category as 3rd column\n",
        "        row_data = {\n",
        "            'id': Path(results['file_path']).stem,\n",
        "            'text': results['extracted_text'],\n",
        "            'category': results.get('category', 'unknown')\n",
        "        }\n",
        "\n",
        "        file_exists = os.path.exists(csv_path)\n",
        "        mode = 'a' if (append and file_exists) else 'w'\n",
        "\n",
        "        with open(csv_path, mode, newline='', encoding='utf-8') as csvfile:\n",
        "            # Order: id, text, category (for model training)\n",
        "            fieldnames = ['id', 'text', 'category']\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "            if not file_exists or not append:\n",
        "                writer.writeheader()\n",
        "\n",
        "            writer.writerow(row_data)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to CSV: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "  # Purpose: Process multiple CV images and save results\n",
        "def process_multiple_cvs(file_paths, csv_path='cv_dataset.csv', save_processed=False, show_details=False):\n",
        "    all_results = []\n",
        "\n",
        "    # If file_paths is a directory, get all images from it\n",
        "    if isinstance(file_paths, str) and os.path.isdir(file_paths):\n",
        "        directory = file_paths\n",
        "        file_paths = []\n",
        "        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}\n",
        "        for file in os.listdir(directory):\n",
        "            if Path(file).suffix.lower() in valid_extensions:\n",
        "                file_paths.append(os.path.join(directory, file))\n",
        "        print(f\"Found {len(file_paths)} images in directory: {directory}\\n\")\n",
        "\n",
        "    # Process each CV\n",
        "    total = len(file_paths)\n",
        "    for idx, file_path in enumerate(file_paths, 1):\n",
        "        if show_details:\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"Processing {idx}/{total}\")\n",
        "            print(f\"{'#'*60}\")\n",
        "        else:\n",
        "            # Show progress without show_details output\n",
        "            print(f\"Processing {idx}/{total}: {Path(file_path).name}\")\n",
        "\n",
        "        # Process the CV\n",
        "        results = process_cv_image(file_path, save_processed=save_processed, show_details=show_details)\n",
        "        all_results.append(results)\n",
        "\n",
        "        # Save to CSV (append mode for all files after first)\n",
        "        append = (idx > 1)\n",
        "        save_to_csv(results, csv_path=csv_path, append=append)\n",
        "\n",
        "        # Also save to text-only CSV\n",
        "        text_csv_path = csv_path.replace('.csv', '_text_only.csv')\n",
        "        save_text_only_csv(results, csv_path=text_csv_path, append=append)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"BATCH PROCESSING COMPLETE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total CVs processed: {total}\")\n",
        "    print(f\"Successful extractions: {sum(1 for r in all_results if 'extracted_text' in r and r['extracted_text'])}\")\n",
        "    print(f\"Results saved to: {csv_path}\")\n",
        "    print(f\"Text-only dataset: {text_csv_path}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Purpose: Get all files from nested folders with category info\n",
        "def get_all_images_from_folders(root_dir):\n",
        "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.pdf', '.docx', '.doc'}\n",
        "    image_files = []\n",
        "\n",
        "    # Walk through all directories and subdirectories\n",
        "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "        for filename in filenames:\n",
        "            if Path(filename).suffix.lower() in valid_extensions:\n",
        "                full_path = os.path.join(dirpath, filename)\n",
        "\n",
        "                # Extract category information from path\n",
        "                rel_path = os.path.relpath(dirpath, root_dir)\n",
        "                path_parts = rel_path.split(os.sep)\n",
        "\n",
        "                # Get main folder and subfolder\n",
        "                main_folder = path_parts[0] if len(path_parts) > 0 else 'unknown'\n",
        "                subfolder = path_parts[-1] if len(path_parts) > 0 else 'unknown'\n",
        "\n",
        "                image_files.append({\n",
        "                    'full_path': full_path,\n",
        "                    'filename': filename,\n",
        "                    'main_folder': main_folder,\n",
        "                    'subfolder': subfolder,\n",
        "                    'category': subfolder  # Use subfolder as category (e.g., \"Accountant\")\n",
        "                })\n",
        "\n",
        "    return image_files\n",
        "\n",
        "\n",
        "# Purpose: Process all images in nested folders and compile results\n",
        "def process_nested_folders(root_dir, csv_path='cv_dataset_all.csv', overwrite=False, save_processed=False, show_details=False):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SCANNING NESTED FOLDERS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Root directory: {root_dir}\\n\")\n",
        "\n",
        "    # Get all image files\n",
        "    image_files = get_all_images_from_folders(root_dir)\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"No image files found!\")\n",
        "        return {'total': 0, 'processed': 0, 'failed': 0}\n",
        "\n",
        "    print(f\"Found {len(image_files)} total images\")\n",
        "\n",
        "    # Count by category\n",
        "    category_counts = {}\n",
        "    for img in image_files:\n",
        "        cat = img['category']\n",
        "        category_counts[cat] = category_counts.get(cat, 0) + 1\n",
        "\n",
        "    print(f\"Found {len(category_counts)} categories:\")\n",
        "    for cat, count in sorted(category_counts.items()):\n",
        "        print(f\"  - {cat}: {count} images\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"STARTING PROCESSING\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Process each image\n",
        "    all_results = []\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    for idx, img_info in enumerate(image_files, 1):\n",
        "        file_path = img_info['full_path']\n",
        "        category = img_info['category']\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"Processing {idx}/{len(image_files)}\")\n",
        "            print(f\"Category: {category}\")\n",
        "            print(f\"{'#'*60}\")\n",
        "        else:\n",
        "            # Show progress with category\n",
        "            print(f\"Processing {idx}/{len(image_files)}: [{category}] {img_info['filename']}\")\n",
        "\n",
        "        # Process the CV\n",
        "        results = process_cv_image(file_path, save_processed=save_processed, show_details=show_details)\n",
        "\n",
        "        # Add category to results\n",
        "        results['category'] = category\n",
        "        results['main_folder'] = img_info['main_folder']\n",
        "        results['subfolder'] = img_info['subfolder']\n",
        "\n",
        "        all_results.append(results)\n",
        "\n",
        "        # Track success/failure\n",
        "        if 'error' not in results and results['extracted_text']:\n",
        "            successful += 1\n",
        "        else:\n",
        "            failed += 1\n",
        "\n",
        "        # We decide the append mode ONCE for the whole function\n",
        "        # If we are NOT overwriting, we must *always* append.\n",
        "        # If we ARE overwriting, we append only *after* the first file.\n",
        "        current_append_mode = True\n",
        "        if overwrite and idx == 1:\n",
        "            current_append_mode = False\n",
        "        save_to_csv(results, csv_path=csv_path, append=current_append_mode)\n",
        "\n",
        "        # Also save to text-only CSV\n",
        "        text_csv_path = csv_path.replace('.csv', '_text_only.csv')\n",
        "        save_text_only_csv(results, csv_path=text_csv_path, append=current_append_mode)\n",
        "\n",
        "    # Print final statistics\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSING COMPLETE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(f\"Successfully extracted: {successful}\")\n",
        "    print(f\"Failed/Empty: {failed}\")\n",
        "    print(f\"Success rate: {(successful/len(image_files)*100):.2f}%\")\n",
        "    print(f\"\\nResults saved to:\")\n",
        "    print(f\"  - Full dataset: {csv_path}\")\n",
        "    print(f\"  - Text only: {text_csv_path}\")\n",
        "\n",
        "    # Statistics by category\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"STATISTICS BY CATEGORY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    category_stats = {}\n",
        "    for result in all_results:\n",
        "        cat = result.get('category', 'unknown')\n",
        "        if cat not in category_stats:\n",
        "            category_stats[cat] = {'total': 0, 'success': 0}\n",
        "        category_stats[cat]['total'] += 1\n",
        "        if 'error' not in result and result.get('extracted_text'):\n",
        "            category_stats[cat]['success'] += 1\n",
        "\n",
        "    for cat in sorted(category_stats.keys()):\n",
        "        stats = category_stats[cat]\n",
        "        success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0\n",
        "        print(f\"{cat:30s}: {stats['success']:4d}/{stats['total']:4d} ({success_rate:5.1f}%)\")\n",
        "\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return {\n",
        "        'total': len(image_files),\n",
        "        'processed': len(all_results),\n",
        "        'successful': successful,\n",
        "        'failed': failed,\n",
        "        'category_stats': category_stats\n",
        "    }\n",
        "\n",
        "\n",
        "# Purpose: Load dataset from CSV for analysis\n",
        "def load_dataset_from_csv(csv_path='cv_dataset.csv'):\n",
        "    try:\n",
        "        dataset = []\n",
        "        with open(csv_path, 'r', encoding='utf-8') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            for row in reader:\n",
        "                dataset.append(row)\n",
        "\n",
        "        print(f\"Loaded {len(dataset)} CV records from {csv_path}\")\n",
        "        return dataset\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CSV: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Purpose: Export all extracted texts to a single text file for NLP tasks\n",
        "def export_texts_for_nlp(csv_path='cv_dataset.csv', output_path='cv_texts.txt'):\n",
        "    try:\n",
        "        dataset = load_dataset_from_csv(csv_path)\n",
        "\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            for record in dataset:\n",
        "                # Replace newlines in text with spaces for single-line format\n",
        "                text = record['extracted_text'].replace('\\n', ' ').strip()\n",
        "                f.write(text + '\\n')\n",
        "\n",
        "        print(f\"Exported {len(dataset)} texts to {output_path}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting texts: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ==================== Main OPTION ====================\n",
        "    results = process_cv_image(\"path/to/file.png\", show_details=False)\n",
        "    text = results['extracted_text']\n",
        "\n",
        "    # Multiple files\n",
        "    for file_path in [\"cv1.png\", \"resume.pdf\", \"doc.docx\"]:\n",
        "        results = process_cv_image(file_path, show_details=False)\n",
        "        text = results.get('extracted_text', '')\n",
        "        print(text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}